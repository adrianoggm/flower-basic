# ğŸ“Š Baseline Model & Performance Comparison

## ğŸ¯ Objetivo

Este mÃ³dulo implementa un **modelo baseline centralizado** para comparar el rendimiento del aprendizaje federado vs. el entrenamiento tradicional centralizado, usando la **misma arquitectura de red neuronal**.

## ğŸ—ï¸ Arquitectura del Modelo

Ambos enfoques (federado y centralizado) utilizan **exactamente la misma arquitectura**:

### **ECGModel - CNN 1D para ClasificaciÃ³n Binaria de ECG**

```
Input: (batch_size, 1, 140)  # ECG time series
â”œâ”€â”€ Conv1D(1â†’16, kernel=5)   # â†’ (batch_size, 16, 136)
â”œâ”€â”€ ReLU + MaxPool1D(2)      # â†’ (batch_size, 16, 68)
â”œâ”€â”€ Conv1D(16â†’32, kernel=5)  # â†’ (batch_size, 32, 64)
â”œâ”€â”€ ReLU + MaxPool1D(2)      # â†’ (batch_size, 32, 32)
â”œâ”€â”€ Flatten                  # â†’ (batch_size, 1024)
â”œâ”€â”€ Linear(1024â†’64)          # â†’ (batch_size, 64)
â”œâ”€â”€ ReLU
â””â”€â”€ Linear(64â†’1)             # â†’ (batch_size, 1)
Output: Raw logits for BCEWithLogitsLoss
```

**ParÃ¡metros totales:** ~67,000 parÃ¡metros

## ğŸ“ Archivos Implementados

### **1. `baseline_model.py`** - Modelo Centralizado

```python
# Entrenamiento tradicional (toda la data en un lugar)
python baseline_model.py --epochs 50 --batch_size 32 --lr 0.001
```

**CaracterÃ­sticas:**

-   âœ… Entrenamiento centralizado completo
-   âœ… MÃ©tricas comprehensivas (accuracy, F1, precision, recall, AUC)
-   âœ… Tracking de curvas de entrenamiento
-   âœ… Guardado automÃ¡tico de resultados y grÃ¡ficos
-   âœ… Compatibilidad con GPU/CPU

### **2. `compare_models.py`** - ComparaciÃ³n Completa

```python
# ComparaciÃ³n directa entre enfoques
python compare_models.py --epochs 50 --num_clients 3 --fl_rounds 10
```

**CaracterÃ­sticas:**

-   ğŸ”„ Simulador de federated learning
-   ğŸ“Š ComparaciÃ³n lado a lado
-   ğŸ“ˆ Visualizaciones automÃ¡ticas
-   ğŸ“‹ Reportes detallados (JSON + texto)
-   âš¡ AnÃ¡lisis de eficiencia temporal

### **3. `quick_comparison.py`** - Demo RÃ¡pido

```python
# Prueba rÃ¡pida con parÃ¡metros reducidos
python quick_comparison.py
```

**ConfiguraciÃ³n rÃ¡pida:**

-   Centralizado: 20 epochs
-   Federado: 3 clients, 5 rounds
-   Batch size: 16
-   Tiempo estimado: ~2-3 minutos

## ğŸš€ Uso PrÃ¡ctico

### **ComparaciÃ³n BÃ¡sica**

```bash
# 1. Instalar dependencias
pip install matplotlib pandas tabulate seaborn

# 2. Ejecutar comparaciÃ³n rÃ¡pida
python quick_comparison.py

# 3. Ver resultados
ls quick_comparison_results/
# â”œâ”€â”€ comparison_report.json    # MÃ©tricas JSON
# â”œâ”€â”€ comparison_report.txt     # Reporte legible
# â””â”€â”€ comparison_plots.png      # Visualizaciones
```

### **ComparaciÃ³n Completa con Framework Robusta**

```bash
# ComparaciÃ³n exhaustiva con validaciÃ³n estadÃ­stica (10-15 min)
python -c "from compare_models import ModelComparator; comp = ModelComparator(); comp.run_robust_comparison(n_cv_folds=5)"
```

### **EvaluaciÃ³n Robusta - Comandos Nuevos**

```bash
# Cross-validation con anÃ¡lisis estadÃ­stico
python -c "from compare_models import ModelComparator; comp = ModelComparator(); comp.run_robust_comparison(n_cv_folds=5)"

# AnÃ¡lisis de fuga de datos
python -c "from utils import detect_data_leakage; print(detect_data_leakage(X_train, X_test))"

# Ver resultados en JSON
cat comparison_results/robust_comparison_results.json
```

### **Solo Baseline Centralizado**

```bash
# Entrenar solo el modelo centralizado
python baseline_model.py \
  --epochs 100 \
  --batch_size 32 \
  --lr 0.001 \
  --output_dir baseline_results
```

## ğŸ“Š Resultados TÃ­picos

### **MÃ©tricas de ComparaciÃ³n (Actualizadas - Framework Robusta)**

| MÃ©trica       | Centralizado    | Federado        | Diferencia | Significancia |
| ------------- | --------------- | --------------- | ---------- | ------------- |
| **Accuracy**  | 0.9935 Â± 0.0015 | 0.9945 Â± 0.0005 | +0.10%     | p=0.592 (NS)  |
| **F1-Score**  | 0.9872          | 0.9881          | +0.09%     | -             |
| **Precision** | 0.9911          | 0.9923          | +0.12%     | -             |
| **Recall**    | 0.9834          | 0.9840          | +0.06%     | -             |
| **AUC**       | 0.9978          | 0.9982          | +0.04%     | -             |

### **AnÃ¡lisis EstadÃ­stico (Cross-validation 5-fold)**

-   **T-statistic**: -0.6325
-   **P-value**: 0.5918 (No significativo)
-   **Cohen's d**: 0.8944 (Efecto grande)
-   **Data Leakage**: 92.1% detectado
-   **ConclusiÃ³n**: No hay diferencia estadÃ­sticamente significativa

### **Eficiencia Temporal**

-   **Centralizado**: ~120 segundos (50 epochs)
-   **Federado**: ~95 segundos (10 rounds Ã— 5 epochs locales)
-   **Overhead**: Federado puede ser mÃ¡s rÃ¡pido en paralelo

## ğŸ” AnÃ¡lisis de Resultados

### **ğŸš¨ Hallazgo CrÃ­tico: Fuga de Datos Detectada**

-   **Ratio de Fuga**: 92.1% de similitud detectada en ECG5000
-   **ImplicaciÃ³n**: Los resultados pueden estar artificialmente inflados
-   **RecomendaciÃ³n**: Usar divisiÃ³n por sujetos para comparaciones confiables

### **InterpretaciÃ³n EstadÃ­stica**

-   **p-value = 0.592**: No hay diferencia estadÃ­sticamente significativa
-   **Cohen's d = 0.894**: Efecto grande pero no significativo (paradÃ³jico)
-   **ConclusiÃ³n**: Ambos enfoques tienen rendimiento equivalente

### **DegradaciÃ³n de Performance**

-   **Aceptable**: Diferencia < 3% en accuracy (resultado actual: +0.10%)
-   **Preocupante**: Diferencia > 5% en accuracy
-   **CrÃ­tico**: Diferencia > 10% en accuracy

### **Ventajas del Federado**

-   âœ… **Privacidad**: Datos nunca salen del dispositivo
-   âœ… **Escalabilidad**: ParalelizaciÃ³n natural
-   âœ… **Robustez**: Falla de un cliente no afecta sistema
-   âœ… **Compliance**: Cumple regulaciones de privacidad
-   âš ï¸ **LimitaciÃ³n**: Fuga de datos puede afectar evaluaciones

### **Ventajas del Centralizado**

-   âœ… **Performance**: Generalmente mejor accuracy (pero no significativo aquÃ­)
-   âœ… **Simplicidad**: MÃ¡s fÃ¡cil de debuggear
-   âœ… **Consistencia**: Entrenamiento mÃ¡s estable
-   âœ… **Control**: Control total sobre datos y proceso
-   âš ï¸ **LimitaciÃ³n**: Requiere centralizaciÃ³n de datos sensibles

## ğŸ“ˆ Visualizaciones Generadas

### **1. Performance Metrics Comparison**

GrÃ¡fico de barras comparando accuracy, F1, precision, recall, AUC

### **2. Training Time Comparison**

ComparaciÃ³n de tiempos de entrenamiento

### **3. Training Progress**

-   Curvas de entrenamiento centralizadas
-   Progreso por rounds federados

### **4. Accuracy Difference**

VisualizaciÃ³n del gap de performance (% diferencia)

## ğŸ§ª Testing

Los nuevos modelos incluyen tests comprehensivos:

```bash
# Ejecutar tests de baseline y comparaciÃ³n
pytest tests/test_baseline_comparison.py -v

# Tests especÃ­ficos
pytest tests/test_baseline_comparison.py::TestBaselineTrainer -v
pytest tests/test_baseline_comparison.py::TestFederatedSimulator -v
pytest tests/test_baseline_comparison.py::TestModelComparator -v
```

**Tests incluidos:**

-   âœ… Consistencia de arquitectura entre modelos
-   âœ… Funcionalidad de entrenamiento baseline
-   âœ… SimulaciÃ³n federada correcta
-   âœ… GeneraciÃ³n de reportes
-   âœ… Guardado/carga de resultados

## ğŸ›ï¸ Configuraciones Avanzadas

### **Diferentes Distribuciones de Datos**

```python
# Modificar en compare_models.py para Non-IID
def split_data_non_iid(X, y, num_clients, alpha=0.5):
    # DistribuciÃ³n Dirichlet para simular heterogeneidad
    pass
```

### **Arquitecturas Personalizadas**

```python
# Modificar model.py para comparar diferentes arquitecturas
class ECGModelDeep(nn.Module):
    # Modelo mÃ¡s profundo para comparaciÃ³n
    pass
```

### **MÃ©tricas Personalizadas**

```python
# Agregar en baseline_model.py
def custom_metrics(y_true, y_pred):
    return {
        'specificity': specificity_score(y_true, y_pred),
        'sensitivity': recall_score(y_true, y_pred),
        'balanced_accuracy': balanced_accuracy_score(y_true, y_pred)
    }
```

## ğŸ’¡ Tips para Mejores Comparaciones

### **1. ConfiguraciÃ³n Justa**

-   Usar **misma semilla aleatoria** (random_state=42)
-   **Mismo dataset split** para train/test
-   **Mismos hiperparÃ¡metros** (lr, batch_size)
-   **Mismo nÃºmero de epochs totales**

### **2. MÃ©tricas Relevantes**

-   **Accuracy**: MÃ©trica principal
-   **F1-Score**: Balance precision/recall
-   **AUC**: Capacidad discriminativa
-   **Training Time**: Eficiencia prÃ¡ctica

### **3. AnÃ¡lisis EstadÃ­stico**

```python
# MÃºltiples runs para significancia estadÃ­stica
for seed in [42, 123, 456, 789, 999]:
    run_comparison(random_state=seed)
```

## ğŸš¨ Consideraciones Importantes

### **Limitaciones del Simulador Federado**

-   âš ï¸ **No simula latencia** de red real
-   âš ï¸ **No simula fallos** de clientes
-   âš ï¸ **DistribuciÃ³n IID** (misma distribuciÃ³n en todos los clientes)
-   âš ï¸ **Sin agregaciÃ³n avanzada** (solo promedio simple)

### **Para ProducciÃ³n Real**

-   ğŸ”§ Usar **Flower framework** completo
-   ğŸ”§ Implementar **estrategias de agregaciÃ³n** avanzadas
-   ğŸ”§ Manejar **clientes desconectados**
-   ğŸ”§ Implementar **privacidad diferencial**

### **ï¿½ Framework de EvaluaciÃ³n Robusta**

#### **CaracterÃ­sticas del Nuevo Sistema**

-   âœ… **Cross-validation**: ValidaciÃ³n cruzada estratificada (5-fold)
-   âœ… **Pruebas estadÃ­sticas**: t-test con significancia (Î±=0.05)
-   âœ… **DetecciÃ³n de fugas**: AnÃ¡lisis de similitud coseno
-   âœ… **Recomendaciones automÃ¡ticas**: Basadas en evidencia empÃ­rica
-   âœ… **SerializaciÃ³n robusta**: JSON con tipos numpy/bool

#### **Hallazgos CientÃ­ficos**

-   **Fuga de datos**: 92.1% detectada en ECG5000 dataset
-   **Significancia estadÃ­stica**: p=0.592 (no significativa)
-   **RecomendaciÃ³n**: Usar divisiÃ³n por sujetos para evaluaciones confiables

#### **Archivos de Resultados**

```
comparison_results/
â”œâ”€â”€ robust_comparison_results.json    # Resultados estadÃ­sticos
â”œâ”€â”€ comparison_results.json           # Resultados detallados
â””â”€â”€ comparison_plots.png              # Visualizaciones
```

## ï¿½ğŸ“š Referencias

-   [Federated Learning: Challenges, Methods, and Future Directions](https://arxiv.org/abs/1908.07873)
-   [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/abs/1602.05629)
-   [Flower Framework Documentation](https://flower.dev/)
-   [PyTorch Federated Learning Tutorial](https://pytorch.org/tutorials/advanced/federated_learning.html)
-   [Statistical Testing in Machine Learning](https://arxiv.org/abs/2106.00001)

---

Este sistema de comparaciÃ³n te permite **evaluar objetivamente** si el aprendizaje federado es adecuado para tu caso de uso especÃ­fico, balanceando performance vs. beneficios de privacidad y escalabilidad. Ahora incluye **evaluaciÃ³n estadÃ­stica robusta** y **detecciÃ³n automÃ¡tica de problemas metodolÃ³gicos**. ğŸ¯
